{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting COVID-19 from chest X-ray images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import relevant libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Libraries to open data\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Torch and PIL libraries for image preprocessing\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# numpy and matplotlib.pyplot to visualize data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# Verbose levels\n",
    "VERBOSE = {\n",
    "    'progress': True,\n",
    "    'augmenting': False,\n",
    "}\n",
    "\n",
    "# Pathnames and filenames\n",
    "DIR = {'data': os.path.join('..', 'data'), 'images': os.path.join('..', 'images')}\n",
    "FILENAMES = {\n",
    "    'X_train': os.path.join(DIR['data'], 'train_images_512.pk'),\n",
    "    'y_train': os.path.join(DIR['data'], 'train_labels_512.pk'),\n",
    "    'X_test': os.path.join(DIR['data'], 'test_images_512.pk'),\n",
    "}\n",
    "\n",
    "# Parameters to load raw data\n",
    "SHIFT, SCALE = 1, 127.5  # data = (data + 1) * 127.5\n",
    "SIZE = {'raw': 512, 'final': 256} # size of raw data and data after downsampling\n",
    "\n",
    "# Relative amount of data used for training vs validation\n",
    "TRAIN_VALID_RATIO = 2 / 1  # i.e. ratio of training data : validation data = 2:1\n",
    "\n",
    "# Parameters for data augmentation\n",
    "N_TRAIN = 100\n",
    "POS_NEG_RATIO = 1 / 1 # negative : positive samples in augmented training set = 1:1\n",
    "\n",
    "# Parameters for data augmentation\n",
    "TRANSFORMATIONS = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomAffine(degrees=15, translate=(0.02, 0.02), scale=(1, 1.15)),\n",
    "    torchvision.transforms.ColorJitter(contrast=0.4, brightness=0.4),\n",
    "    torchvision.transforms.RandomErasing(p=0.3, scale=(0.01, 0.03), ratio=(1 / 3, 3)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Define functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# Function to print progress\n",
    "def verbose_print(message, print_flag, end='\\n'):\n",
    "    if print_flag:\n",
    "        print(message, end=end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# Functions to load data\n",
    "def load_pk(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f, encoding='bytes')\n",
    "\n",
    "def load_X(filename):\n",
    "    X = load_pk(filename)\n",
    "    assert X.size(2) == X.size(3) == SIZE['raw']\n",
    "    return SCALE * (X[:, :1, :, :] + SHIFT)\n",
    "\n",
    "def load_y(filename):\n",
    "    y = load_pk(filename)\n",
    "    return y.type(torch.long)  # convert to integer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# Functions to preprocess data\n",
    "def downsample(X):\n",
    "    f = SIZE['raw'] // SIZE['final']\n",
    "    for i in range(SIZE['final']):\n",
    "        for j in range(SIZE['final']):\n",
    "            X[:, :, i, j] = X[:, :, i * f:(i + 1) * f, j * f:(j + 1)*f].mean(-1).mean(-1)\n",
    "    return X[:, :, :SIZE['final'], :SIZE['final']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# Function to split data into training and validation sets\n",
    "def split_train_valid(X, y):\n",
    "    def split(X, y, f):\n",
    "        idx, k = torch.randperm(y.size(0)), round(y.size(0) * f)\n",
    "        return X[idx[:k]], y[idx[:k]], X[idx[k:]], y[idx[k:]]\n",
    "    f = TRAIN_VALID_RATIO / (1 + TRAIN_VALID_RATIO)\n",
    "    X_train_0, y_train_0, X_valid_0, y_valid_0 = split(X[y == 0], y[y == 0], f)\n",
    "    X_train_1, y_train_1, X_valid_1, y_valid_1 = split(X[y == 1], y[y == 1], f)\n",
    "    X_train, y_train = torch.cat((X_train_0, X_train_1)), torch.cat((y_train_0, y_train_1))\n",
    "    X_valid, y_valid = torch.cat((X_valid_0, X_valid_1)), torch.cat((y_valid_0, y_valid_1))\n",
    "    return X_train, y_train, X_valid, y_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Function to augment training data\n",
    "def augment(X_in, y_in, transform_fn):\n",
    "    def transform(im_):\n",
    "        while True:\n",
    "            try:\n",
    "                return transform_fn(im_)\n",
    "            except AttributeError:\n",
    "                verbose_print(f'Something went wrong', VERBOSE['augmenting'])\n",
    "                continue\n",
    "    X_out, y_out = torch.zeros(N_TRAIN, 1, SIZE['final'], SIZE['final']), torch.zeros(N_TRAIN)\n",
    "    f = POS_NEG_RATIO / (1 + POS_NEG_RATIO)\n",
    "    for i in range(N_TRAIN):\n",
    "        label = int(torch.rand(1, 1) > f)\n",
    "        X = X_in[y_in == label]\n",
    "        choice = int(torch.randint(0, X.size(0), (1, 1)))\n",
    "        im = torchvision.transforms.functional.to_pil_image(X[choice])\n",
    "        X_out[i], y_out[i] = transform(im), label\n",
    "    return X_out, y_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# Function to visualize transformed training data\n",
    "def display(X, h=4, w=5):\n",
    "    s = SIZE['final']\n",
    "    im = np.empty((1, h * s, w * s))\n",
    "    idx = np.random.choice(X.size(0), (h, w), replace=False)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            # print(X[idx].size())\n",
    "            # print(im.shape, np.array(X[idx]).shape)\n",
    "            im[:, s * i:s * (i + 1), s * j:s * (j + 1)] = np.array(X[idx[i, j]])\n",
    "    plt.imshow(im.transpose((1, 2, 0)).repeat(3, 2))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# def show_train_image(idx=None):\n",
    "#     if idx is None:\n",
    "#         idx = int(torch.randint(0, y_train.shape[0], (1,)))\n",
    "#     im = np.array(X_train[idx][None, :, :]).transpose((1, 2, 0)).repeat(3, 2)\n",
    "#     label = int(y_train[idx])\n",
    "#     print(f'Label: {label:d} (X_train[{idx:d}])')\n",
    "#     plt.imshow(im)\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Load and preprocess data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loading data...               DONE\n",
      "torch.Size([70, 1, 512, 512])\n",
      "torch.Size([70])\n",
      "torch.Size([20, 1, 512, 512])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Load raw data\n",
    "verbose_print(f'{\"Loading data...\":30s}', VERBOSE['progress'], end='')\n",
    "X_train = load_X(FILENAMES['X_train'])\n",
    "y_train = load_y(FILENAMES['y_train'])\n",
    "X_test = load_X(FILENAMES['X_test'])\n",
    "verbose_print('DONE', VERBOSE['progress'])\n",
    "\n",
    "print(X_train.size())\n",
    "print(y_train.size())\n",
    "print(X_test.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Downsampling data...          DONE\n",
      "torch.Size([70, 1, 256, 256])\n",
      "torch.Size([20, 1, 256, 256])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Downsample data\n",
    "verbose_print(f'{\"Downsampling data...\":30s}', VERBOSE['progress'], end='')\n",
    "X_train = downsample(X_train)\n",
    "X_test = downsample(X_test)\n",
    "verbose_print('DONE', VERBOSE['progress'])\n",
    "\n",
    "print(X_train.size())\n",
    "print(X_test.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Splitting data...             DONE\n",
      "torch.Size([47, 1, 256, 256])\n",
      "torch.Size([47])\n",
      "torch.Size([23, 1, 256, 256])\n",
      "torch.Size([23])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Split training data into training and validation sets\n",
    "verbose_print(f'{\"Splitting data...\":30s}', VERBOSE['progress'], end='')\n",
    "X_train, y_train, X_valid, y_valid = split_train_valid(X_train, y_train)\n",
    "verbose_print('DONE', VERBOSE['progress'])\n",
    "\n",
    "print(X_train.size())\n",
    "print(y_train.size())\n",
    "print(X_valid.size())\n",
    "print(y_valid.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Splitting data...             DONE\n",
      "torch.Size([100, 1, 256, 256])\n",
      "torch.Size([100])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Augment data\n",
    "verbose_print(f'{\"Splitting data...\":30s}', VERBOSE['progress'], end='')\n",
    "X_train, y_train = augment(X_train, y_train, TRANSFORMATIONS)\n",
    "verbose_print('DONE', VERBOSE['progress'])\n",
    "\n",
    "print(X_train.size())\n",
    "print(y_train.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-62ab494fa84c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-c6a55502ced0>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(X, h, w)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 11 is out of bounds for dimension 1 with size 1"
     ],
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for dimension 1 with size 1",
     "output_type": "error"
    }
   ],
   "source": [
    "display(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}